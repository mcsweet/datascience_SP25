}
## Check datatypes
assertthat::assert_that(is.numeric(df_normalized$cases))
assertthat::assert_that(is.numeric(df_normalized$deaths))
assertthat::assert_that(is.numeric(df_normalized$population))
assertthat::assert_that(is.numeric(df_normalized$cases_per100k))
assertthat::assert_that(is.numeric(df_normalized$deaths_per100k))
## Check that normalization is correct
assertthat::assert_that(
abs(df_normalized %>%
filter(
str_detect(county, "Snohomish"),
date == "2020-01-21"
) %>%
pull(cases_per100k) - 0.127) < 1e-3
)
assertthat::assert_that(
abs(df_normalized %>%
filter(
str_detect(county, "Snohomish"),
date == "2020-01-21"
) %>%
pull(deaths_per100k) - 0) < 1e-3
)
print("Excellent!")
## TASK: Compute mean and sd for cases_per100k and deaths_per100k
df_normalized %>%
filter(deaths_per100k >= 0) %>%
filter(cases_per100k >= 0) %>%
summarise(
mean_cases_per100k = mean(cases_per100k),
sd_cases_per100k = sd(cases_per100k),
mean_deaths_per100k = mean(deaths_per100k),
sd_deaths_per100k = sd(deaths_per100k)
)
## TASK: Find the top 10 max cases_per100k counties; report populations as well
df_top10_cases <-
df_normalized %>%
group_by(county) %>%
summarise(across(c(cases_per100k, population), max)) %>%
arrange(desc(cases_per100k)) %>%
slice(0:10)
## TASK: Find the top 10 deaths_per100k counties; report populations as well
df_top10_deaths <-
df_normalized %>%
group_by(county) %>%
summarise(across(c(deaths_per100k, population), max)) %>%
arrange(desc(deaths_per100k)) %>%
slice(0:10)
df_top10_cases
df_top10_deaths
counties_NE = c("Middlesex","Fairfield","Hartford","New Haven","Worcester","Essex", "Suffolk","Norfolk", "Providence","Bristol","Plymouth","Hampden","Hillsborough","Rockingham","Cumberland","New London","Barnstable","York","Litchfield","Kent","Middlesex","Hampshire","Chittenden","Penobscot","Tolland","Merrimack","Berkshire","Washington","Strafford","Kennebec","Windham","Androscoggin","Grafton","Newport","Cheshire","Franklin","Aroostook","Belknap","Rutland","Washington","Oxford","Windsor","Hancock","Somerset","Bristol","Franklin","Carroll","Windham","Sullivan","Knox")
df_normalized_NE <-
df_normalized %>%
filter(state %in% c("Connecticut", "Maine", "Massachusetts", "New Hampshire", "Rhode Island", "Vermont")) %>%
filter(county %in% counties_NE)
df_normalized_NE %>%
filter(deaths_per100k >= 0) %>%
filter(cases_per100k >= 0) %>%
summarise(
mean_cases_per100k = mean(cases_per100k),
sd_cases_per100k = sd(cases_per100k),
mean_deaths_per100k = mean(deaths_per100k),
sd_deaths_per100k = sd(deaths_per100k) )
white_county_names <- c("Carroll", "Somerset" , "Rutland", "Oxford", "Knox", "Sullivan", "Hancock", "Belknap", "Windsor", "Kennebec")
df_top10_cases_white_NE <-
df_normalized %>%
group_by(county) %>%
filter(county %in% white_county_names) %>%
summarise(across(c(cases_per100k, population), mean)) %>%
arrange(desc(cases_per100k)) %>%
slice(0:10)
## TASK: Find the top 10 deaths_per100k counties; report populations as well
df_top10_deaths_white_NE <-
df_normalized %>%
group_by(county) %>%
filter(county %in% white_county_names) %>%
summarise(across(c(deaths_per100k, population), mean)) %>%
arrange(desc(deaths_per100k)) %>%
slice(0:10)
POC_county_names <- c("Suffolk", "Providence", "Hartford", "Fairfield", "Hampden", "New Haven", "Essex", "Middlesex", "New London", "Norfolk")
df_top10_cases_POC_NE <-
df_normalized %>%
group_by(county) %>%
filter(county %in% POC_county_names) %>%
summarise(across(c(cases_per100k, population), mean)) %>%
arrange(desc(cases_per100k)) %>%
slice(0:10)
## TASK: Find the top 10 deaths_per100k counties; report populations as well
df_top10_deaths_POC_NE <-
df_normalized %>%
group_by(county) %>%
filter(county %in% POC_county_names) %>%
summarise(across(c(deaths_per100k, population), mean)) %>%
arrange(desc(deaths_per100k)) %>%
slice(0:10)
df_top10_cases_POC_NE
df_top10_cases_white_NE
df_top10_deaths_POC_NE
df_top10_deaths_white_NE
df_normalized_NE %>%
group_by(county) %>%
summarise(across(c(cases_per100k, population), mean)) %>%
ggplot() +
geom_point(aes(cases_per100k, population, color = "NE trend")) +
geom_point(data = df_top10_cases_POC_NE, aes(cases_per100k, population,color = "POC")) +
geom_point(data = df_top10_cases_white_NE, aes(cases_per100k, population, color = "White")) +
labs(
x = "Cases per 100k",
y = "Population",
color = "Legend") +
scale_color_manual(values = c("NE trend" = "yellow", "POC" = "blue","White" = "red"))
df_normalized_NE %>%
group_by(county) %>%
summarise(across(c(deaths_per100k, population), mean)) %>%
ggplot() +
geom_point(aes(deaths_per100k, population, color = "NE trend")) +
geom_point(data = df_top10_deaths_POC_NE, aes(deaths_per100k, population,color = "POC")) +
geom_point(data = df_top10_deaths_white_NE, aes(deaths_per100k, population, color = "White")) +
labs(
x = "Deaths per 100k",
y = "Population",
color = "Legend") +
scale_color_manual(values = c("NE trend" = "yellow","POC" = "blue","White" = "red"))
df_normalized_NE <-
df_normalized_NE %>%
mutate("Race_Dominant" = case_when(
county %in% white_county_names ~ "White Dominant",
county %in% POC_county_names   ~ "POC Dominant",
TRUE ~ "NE Trend"
))
df_normalized_NE %>%
group_by(county) %>%
ggplot(aes(date,cases_per100k)) +
geom_smooth(aes(color = Race_Dominant), linetype = 1) +
scale_y_log10() +
labs(
x = "Date",
y = "Cases (Per 100,000 People)",
color = "Legend")
df_normalized_NE %>%
group_by(county) %>%
ggplot(aes(date,deaths_per100k)) +
geom_smooth(aes(color = Race_Dominant), linetype = 1) +
scale_y_log10() +
labs(
x = "Date",
y = "Deaths (Per 100,000 People)",
color = "Legend")
df_data_NE <-
df_data %>%
filter(state %in% c("Connecticut", "Maine", "Massachusetts", "New Hampshire", "Rhode Island", "Vermont")) %>%
filter(county %in% counties_NE)
df_data_NE %>%
filter(deaths >= 0) %>%
filter(cases>= 0) %>%
summarise(
mean_cases  = mean(cases),
sd_cases    = sd(cases),
mean_deaths = mean(deaths),
sd_deathsk  = sd(deaths)
)
#Add in collum for if white_county_names, POC_county_names, or other to the df_data_NE data set
df_data_NE_Race <-
df_data_NE %>%
mutate("Race_Dominant" = case_when(
county %in% white_county_names ~ "White Dominant",
county %in% POC_county_names   ~ "POC Dominant",
TRUE ~ "Other"
))
df_data_NE_Race %>%
group_by(county, Race_Dominant) %>%
summarise(across(c(cases, population), mean)) %>%
ggplot(aes(cases, population)) +
geom_point(aes(color = Race_Dominant)) +
geom_smooth() +
scale_y_log10() +
scale_x_log10() +
labs(
x = "Cases",
y = "Population",
color = "Legend"
)
df_data_NE_Race %>%
group_by(county, Race_Dominant) %>%
summarise(across(c(deaths, population), mean)) %>%
ggplot(aes(deaths, population)) +
geom_point(aes(color = Race_Dominant)) +
geom_smooth() +
scale_y_log10() +
scale_x_log10() +
labs(
x = "Deaths",
y = "Population",
color = "Legend"
)
## NOTE: No need to change this; just an example
df_normalized %>%
filter(
state == "Massachusetts", # Focus on Mass only
!is.na(fips), # fct_reorder2 can choke with missing data
) %>%
ggplot(
aes(date, cases_per100k, color = fct_reorder2(county, date, cases_per100k))
) +
geom_line() +
scale_y_log10() +
scale_color_discrete(name = "County") +
theme_minimal() +
labs(
x = "Date",
y = "Cases (per 100,000 persons)"
)
## TASK: Join df_covid and df_q3 by fips.
df_q4 <- merge(df_covid, df_q3, by = "fips")
## TASK: Join df_covid and df_q3 by fips.
#df_q4 <- merge(df_covid, df_q3, by = "fips")
df_q4<- left_join(df_I, df_r, by = "fips")
## TASK: Join df_covid and df_q3 by fips.
#df_q4 <- merge(df_covid, df_q3, by = "fips")
df_q4<- left_join(df_covid, df_q3, by = "fips")
## NOTE: No need to change this
if (!any(df_q4 %>% pull(fips) %>% str_detect(., "02105"), na.rm = TRUE)) {
assertthat::assert_that(TRUE)
} else {
print(str_c(
"Your df_q4 contains a row for the Hoonah-Angoon Census Area (AK),",
"which is not in df_covid. You used the incorrect join type.",
sep = " "
))
assertthat::assert_that(FALSE)
}
if (any(df_q4 %>% pull(fips) %>% str_detect(., "78010"), na.rm = TRUE)) {
assertthat::assert_that(TRUE)
} else {
print(str_c(
"Your df_q4 does not include St. Croix, US Virgin Islands,",
"which is in df_covid. You used the incorrect join type.",
sep = " "
))
assertthat::assert_that(FALSE)
}
print("Very good!")
library(tidyverse)
library(MASS)
library(broom)
diamonds %>%
select(carat, cut) %>%
glimpse()
diamonds %>%
dplyr::select(carat, cut) %>%
glimpse()
## NOTE: No need to edit this setup
set.seed(101)
df_data_norm <- tibble(x = rnorm(50, mean = 2, sd = 1))
## NOTE: Example use of fitdistr()
df_est_norm <-
df_data_norm %>%
pull(x) %>%
fitdistr(densfun = "normal") %>%
tidy()
df_est_norm
## TASK: Compute the sample mean and sd of `df_data_norm %>% pull(x)`
mean_est <- df_data_norm %>% pull(x) %>%  mean()
sd_est <- df_data_norm %>%  pull(x) %>%  sd()
mean_est
sd_est
## TASK: Compute the sample mean and sd of `df_data_norm %>% pull(x)`
mean_est <- df_data_norm %>% pull(x) %>%  mean()
sd_est <- df_data_norm %>%  pull(x) %>%  sd()
mean_est
sd_est
## NOTE: No need to edit this setup
set.seed(101)
df_data_weibull <- tibble(y = rweibull(50, shape = 2, scale = 4))
## TASK: Use the `fitdistr()` function to estimate parameters
df_q2 <-
df_data_weibull %>%
pull(x) %>%
fitdistr(densfun = "weibull") %>%
tidy()
## NOTE: No need to edit this setup
set.seed(101)
df_data_weibull <- tibble(y = rweibull(50, shape = 2, scale = 4))
## TASK: Use the `fitdistr()` function to estimate parameters
df_q2 <-
df_data_weibull %>%
pull(y) %>%
fitdistr(densfun = "weibull") %>%
tidy()
df_q2
## NOTE: No need to modify this line
pr_true <- pweibull(q = 2, shape = 2, scale = 4)
## TASK: Extract the parameter estimates from df_q2 and estimate Pr[Y <= 2]
pr_est <-
df_q2 %>%
summarize(
shape_est,
scale_est
)
## NOTE: No need to modify this line
pr_true <- pweibull(q = 2, shape = 2, scale = 4)
## TASK: Extract the parameter estimates from df_q2 and estimate Pr[Y <= 2]
set.seed(101)
shape_est <-
df_q2 %>%
filter(term == "shape") %>%
pull (estimate)
scale_est <-
df_q2 %>%
filter(term == "scale") %>%
pull (estimate)
pr_est <- pweibull(q = 2, shape = shape_est, scale = scale_est)
pr_true
pr_est
## NOTE: No need to modify this line
pr_true <- pweibull(q = 2, shape = 2, scale = 4)
## TASK: Extract the parameter estimates from df_q2 and estimate Pr[Y <= 2]
set.seed(101)
shape_est <-
df_q2 %>%
filter(term == "shape") %>%
pull (estimate)
scale_est <-
df_q2 %>%
filter(term == "scale") %>%
pull (estimate)
pr_est <- pweibull(q = 2, shape = shape_est, scale = scale_est)
pr_true
pr_est
## Note: No need to edit this chunk!
library(tidyverse)
set.seed(101)
df_meas <-
map_dfr(
1:30,
function(i) {
Y_deviation <- rlnorm(n = 1, meanlog = 2)
Y_noise <- rnorm(n = 5, sd = 1)
tibble(Y = Y_deviation + Y_noise) %>%
mutate(id_sample = i, id_meas = row_number())
}
)
df_meas %>%
ggplot(aes(Y)) +
geom_histogram(bins = 30)
set.seed(101)
df_meas <-
map_dfr(
1:30,
function(i) {
Y_deviation <- rlnorm(n = 1, meanlog = 2)
Y_noise <- rnorm(n = 5, sd = 1)
tibble(Y = Y_deviation + Y_noise) %>%
mutate(id_sample = i, id_meas = row_number())
}
)
df_meas %>%
ggplot(aes(Y)) +
geom_histogram(bins = 30)
## NOTE: No need to edit; run and inspect
df_meas %>%
ggplot(aes(id_sample, Y)) +
geom_point(
data = . %>%
group_by(id_sample) %>%
summarize(Y = mean(Y)),
color = "red",
size = 1
) +
geom_point(size = 0.2) +
theme_minimal()
library(tidyverse)
## NOTE: No need to edit; run and inspect
url_disease <- "http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
filename_disease <- "./data/uci_heart_disease.csv"
## Download the data locally
curl::curl_download(
url_disease,
destfile = filename_disease
)
## NOTE: No need to edit; run and inspect
read_csv(filename_disease) %>% glimpse()
## TODO: Assign the column names to col_names; make sure they are strings
col_names <- c(
"age",
"sex",
"cp",
"trestbps",
"chol",
"fbs",
"restecg",
"thalach",
"exang",
"oldpeak",
"slope",
"ca",
"thal",
"num"
)
## NOTE: No need to change this
assertthat::assert_that(col_names[1] == "age")
assertthat::assert_that(col_names[2] == "sex")
assertthat::assert_that(col_names[3] == "cp")
assertthat::assert_that(col_names[4] == "trestbps")
assertthat::assert_that(col_names[5] == "chol")
assertthat::assert_that(col_names[6] == "fbs")
assertthat::assert_that(col_names[7] == "restecg")
assertthat::assert_that(col_names[8] == "thalach")
assertthat::assert_that(col_names[9] == "exang")
assertthat::assert_that(col_names[10] == "oldpeak")
assertthat::assert_that(col_names[11] == "slope")
assertthat::assert_that(col_names[12] == "ca")
assertthat::assert_that(col_names[13] == "thal")
assertthat::assert_that(col_names[14] == "num")
print("Well done!")
## TODO: Use the col_names and col_types arguments to give the data the
##       correct column names, and to set their types to col_number()
df_q2 <-
read_csv(
filename_disease,
col_names = col_names,
col_types = cols(
"age" = col_number(),
"sex" = col_number(),
"cp" = col_number(),
"trestbps" = col_number(),
"chol" = col_number(),
"fbs" = col_number(),
"restecg" = col_number(),
"thalach" = col_number(),
"exang" = col_number(),
"oldpeak" = col_number(),
"slope" = col_number(),
"ca" = col_number(),
"thal" = col_number(),
"num" = col_number()
)
)
df_q2 %>% glimpse()
## NOTE: No need to change this
assertthat::assert_that(assertthat::are_equal(names(df_q2), col_names))
assertthat::assert_that(all(map_chr(df_q2, class) == "numeric"))
print("Nice!")
## NOTE: This is an example conversion
convert_sex <- function(x) {
case_when(
x == 1 ~ "male",
x == 0 ~ "female",
TRUE ~ NA_character_
)
}
## TODO: Complete the remaining conversion functions
convert_cp <- NA
convert_fbs <- NA
convert_restecv <- NA
convert_exang <- NA
convert_slope <- NA
convert_thal <- NA
## NOTE: This is an example conversion
convert_sex <- function(x) {
case_when(
x == 1 ~ "male",
x == 0 ~ "female",
TRUE ~ NA_character_
)
}
## TODO: Complete the remaining conversion functions
convert_cp <- function(x) {
case_when(
x == 1 ~ "typical angina",
x == 2 ~ "atypical agina",
x == 3 ~ "non-anginal pain",
x == 4 ~ "asymptomatic",
TRUE ~ NA_character_
)
}
convert_fbs <- function(x) {
if_else(x == 1, TRUE, FALSE)
}
convert_restecv <- function(x) {
case_when(
x == 0 ~ "normal",
x == 1 ~ "ST-T wave abnormality",
x == 2 ~ "Estes' criteria",
TRUE ~ NA_character_
)
}
convert_exang <- function(x) {
if_else(x == 1, TRUE, FALSE)
}
convert_slope <- function(x) {
case_when(
x == 1 ~ "upsloping",
x == 2 ~ "flat",
x == 3 ~ "downsloping",
TRUE ~ NA_character_
)
}
convert_thal <- function(x) {
case_when(
x == 3 ~ "normal",
x == 6 ~ "fixed defect",
x == 7 ~ "reversible defect",
TRUE ~ NA_character_
)
}
## NOTE: No need to change this
assertthat::assert_that(assertthat::are_equal(
convert_cp(c(1, 2, 3, 4)),
c("typical angina", "atypical angina", "non-anginal pain", "asymptomatic")
))
