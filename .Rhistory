scale_x_log10() +
labs(
x = "Deaths",
y = "Population",
color = "Legend"
)
library(tidyverse)
library(readxl) # For reading Excel sheets
## TASK: Join df_covid and df_q3 by fips.
df_q4 <- merge(df_covid, df_q3, by = "fips")
## NOTE: No need to change this; just execute
df_pop %>% glimpse
## NOTE: No need to change this; just execute
df_pop %>% glimpse
## NOTE: No need to change this; just execute
## Set the filename of the data to download
filename_nyt <- "./data/nyt_counties.csv"
## Download the data locally
curl::curl_download(
url_counties,
destfile = filename_nyt
)
## TASK: Find the URL for the NYT covid-19 county-level data
url_counties <- "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"
## TASK: Load the census bureau data with the following tibble name.
## TASK: Load the census bureau data with the following tibble name.
filename <- "./data/Pop_Data.csv"
df_pop <- read_csv(filename, skip = 2, na = "*****", col_types = "ccd_d__", col_names = c("id", "Geographic Area Name", "Estimate!!Total", "Margin of Error!!Total"))
## TASK: Find the URL for the NYT covid-19 county-level data
url_counties <- "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"
## NOTE: No need to change this; just execute
## Set the filename of the data to download
filename_nyt <- "./data/nyt_counties.csv"
## Download the data locally
curl::curl_download(
url_counties,
destfile = filename_nyt
)
## Loads the downloaded csv
df_covid <- read_csv(filename_nyt)
## NOTE: No need to change this; just execute
df_pop %>% glimpse
df_covid %>% glimpse
## TASK: Create a `fips` column by extracting the county code
df_q3 <-
df_pop %>%
mutate(fips = str_extract(id, "[^US]*$"))
head(df_q3)
## NOTE: No need to change this
## Check known county
assertthat::assert_that(
(df_q3 %>%
filter(str_detect(`Geographic Area Name`, "Autauga County")) %>%
pull(fips)) == "01001"
)
print("Very good!")
## TASK: Join df_covid and df_q3 by fips.
df_q4 <- merge(df_covid, df_q3, by = "fips")
## NOTE: No need to change this
if (!any(df_q4 %>% pull(fips) %>% str_detect(., "02105"), na.rm = TRUE)) {
assertthat::assert_that(TRUE)
} else {
print(str_c(
"Your df_q4 contains a row for the Hoonah-Angoon Census Area (AK),",
"which is not in df_covid. You used the incorrect join type.",
sep = " "
))
assertthat::assert_that(FALSE)
}
if (any(df_q4 %>% pull(fips) %>% str_detect(., "78010"), na.rm = TRUE)) {
assertthat::assert_that(TRUE)
} else {
print(str_c(
"Your df_q4 does not include St. Croix, US Virgin Islands,",
"which is in df_covid. You used the incorrect join type.",
sep = " "
))
assertthat::assert_that(FALSE)
}
## NOTE: No need to change this
if (!any(df_q4 %>% pull(fips) %>% str_detect(., "02105"), na.rm = TRUE)) {
assertthat::assert_that(TRUE)
} else {
print(str_c(
"Your df_q4 contains a row for the Hoonah-Angoon Census Area (AK),",
"which is not in df_covid. You used the incorrect join type.",
sep = " "
))
assertthat::assert_that(FALSE)
}
# if (any(df_q4 %>% pull(fips) %>% str_detect(., "78010"), na.rm = TRUE)) {
#   assertthat::assert_that(TRUE)
# } else {
#   print(str_c(
#     "Your df_q4 does not include St. Croix, US Virgin Islands,",
#     "which is in df_covid. You used the incorrect join type.",
#     sep = " "
#   ))
#   assertthat::assert_that(FALSE)
# }
#
print("Very good!")
library(tidyverse)
library(nycflights13)
## TASK: Estimate a 99% confidence interval with the sample below
set.seed(101)
z_q1 <- rnorm(n = 100, mean = 1, sd = 2)
lo_q1 <- NA_real_
hi_q1 <- NA_real_
## NOTE: No need to change this!
assertthat::assert_that(abs(lo_q1 - 0.4444163) < 1e-6)
## NOTE: No need to change this!
z_c <- qnorm( 1 - (1 - 0.95) / 2 )
z_c
## NOTE: No need to change this!
-qnorm(0.05 / 2) # The same value as qnorm( 1 - (1 - 0.95) / 2 )
## NOTE: No need to change this!
df_clt %>%
filter(n > 1) %>%
mutate(
se = sd / sqrt(n),
lo = mean - z_c * se,
hi = mean + z_c * se,
flag = (lo <= 0.5) & (0.5 <= hi)
) %>%
group_by(n) %>%
summarize(coverage = mean(flag))
library(tidyverse)
library(nycflights13)
## NOTE: No need to edit this
set.seed(101)
n_observations <- 9
n_samples <- 5e3
df_samp_unif <-
map_dfr(
1:n_samples,
function(id) {
tibble(
Z = runif(n_observations),
id = id
)
}
)
df_samp_unif %>%
group_by(id) %>%
summarize(stat = mean(Z)) %>%
ggplot(aes(stat)) +
geom_histogram() +
labs(
x = "Estimated Mean",
title = "Sampling Distribution: Estimated Mean",
caption = "Population: Uniform"
)
## NOTE: No need to change this!
set.seed(101)
n_repl <- 5e3
df_clt <-
map_dfr(
1:n_repl,
function(id) {
map_dfr(
c(1, 2, 9, 81, 729),
function(n) {
tibble(
Z = runif(n),
n = n,
id = id
)
}
)
}
) %>%
group_by(n, id) %>%
summarize(mean = mean(Z), sd = sd(Z))
df_clt %>%
ggplot(aes(mean)) +
geom_density() +
facet_wrap(~n, scales = "free")
## NOTE: No need to change this!
z_c <- qnorm( 1 - (1 - 0.95) / 2 )
z_c
## NOTE: No need to change this!
-qnorm(0.05 / 2) # The same value as qnorm( 1 - (1 - 0.95) / 2 )
## NOTE: No need to change this!
df_clt %>%
filter(
n > 1,
id <= 100
) %>%
mutate(
se = sd / sqrt(n),
lo = mean - z_c * se,
hi = mean + z_c * se
) %>%
ggplot(aes(id)) +
geom_hline(yintercept = 0.5, linetype = 2) +
geom_errorbar(aes(
ymin = lo,
ymax = hi,
color = (lo <= 0.5) & (0.5 <= hi)
)) +
facet_grid(n~.) +
scale_color_discrete(name = "CI Contains True Mean") +
theme(legend.position = "bottom") +
labs(
x = "Replication",
y = "Estimated Mean"
)
## NOTE: No need to change this!
set.seed(101)
n_repl <- 5e3
df_clt <-
map_dfr(
1:n_repl,
function(id) {
map_dfr(
c(1, 2, 9, 81, 729),
function(n) {
tibble(
Z = runif(n),
n = n,
id = id
)
}
)
}
) %>%
group_by(n, id) %>%
summarize(mean = mean(Z), sd = sd(Z))
## NOTE: No need to change this!
df_clt %>%
filter(n > 1) %>%
mutate(
se = sd / sqrt(n),
lo = mean - z_c * se,
hi = mean + z_c * se,
flag = (lo <= 0.5) & (0.5 <= hi)
) %>%
group_by(n) %>%
summarize(coverage = mean(flag))
## NOTE: No need to change this!
df_flights_aa <-
flights %>%
filter(carrier == "AA") %>%
summarize(across(
arr_delay,
c(
"mean" = ~mean(., na.rm = TRUE),
"sd" = ~sd(., na.rm = TRUE),
"n" = ~length(.)
)
))
df_flights_aa
## NOTE: No need to change this!
set.seed(101)
# Downsample at different sample sizes, construct a confidence interval
df_flights_sampled <-
map_dfr(
c(5, 10, 25, 50, 100, 250, 500), # Sample sizes
function(n) {
flights %>%
filter(carrier == "AA") %>%
slice_sample(n = n) %>%
summarize(across(
arr_delay,
c(
"mean" = ~mean(., na.rm = TRUE),
"se" = ~sd(., na.rm = TRUE) / length(.)
)
)) %>%
mutate(
arr_delay_lo = arr_delay_mean - 1.96 * arr_delay_se,
arr_delay_hi = arr_delay_mean + 1.96 * arr_delay_se,
n = n
)
}
)
# Visualize
df_flights_sampled %>%
ggplot(aes(n, arr_delay_mean)) +
geom_hline(
data = df_flights_aa,
mapping = aes(yintercept = arr_delay_mean),
size = 0.1
) +
geom_hline(yintercept = 0, color = "white", size = 2) +
geom_errorbar(aes(
ymin = arr_delay_lo,
ymax = arr_delay_hi,
color = (0 < arr_delay_lo)
)) +
geom_point() +
scale_x_log10() +
scale_color_discrete(name = "Confidently Greater than Zero?") +
theme(legend.position = "bottom") +
labs(
x = "Observations",
y = "Arrival Delay (minutes)",
title = "American Airlines Delays"
)
library(tidyverse)
library(rsample)
## NOTE: No need to change this!
df_population <-
diamonds %>%
filter(carat < 1)
## NOTE: No need to change this!
set.seed(101)
df_sample <-
df_population %>%
slice_sample(n = 100)
## NOTE: No need to change this; this will be our decision threshold
price_threshold <- 1700
## NOTE: No need to change this; this will be our decision threshold
price_threshold <- 1700
library(tidyverse)
# knitr options
knitr::opts_chunk$set(echo = TRUE)
economics %>%
pivot_longer(
names_to = "variable",
values_to = "value",
cols = c(pce, pop, psavert, uempmed, unemploy)
) %>%
ggplot(aes(date, value)) +
geom_line() +
facet_wrap(~variable, scales = "free_y")
## NOTE: No need to edit; study this example
mpg %>%
ggplot(aes(displ, hwy)) +
geom_point() +
facet_wrap(~class)
## NOTE: No need to edit; study this example
mpg %>%
ggplot(aes(displ, hwy)) +
## A bit of a trick; remove the facet variable to prevent faceting
geom_point(
data = . %>% select(-class),
color = "grey80"
) +
geom_point() +
facet_wrap(~class) +
theme_minimal()
## TODO: Edit this code to facet on `cut`, but keep "ghost" points to aid in
## comparison.
diamonds %>%
ggplot(aes(carat, price)) +
geom_point(
data = . %>% select(-cut),
color = "grey80"
) +
geom_point() +
facet_wrap(~cut)
mpg %>%
group_by(model) %>%
filter(row_number(desc(year)) == 1) %>%
ungroup() %>%
mutate(
manufacturer = fct_reorder(manufacturer, hwy),
model = fct_reorder(model, desc(hwy))
) %>%
ggplot(aes(hwy, model)) +
geom_point() +
facet_grid(manufacturer~., scale = "free_y", space = "free") +
theme(
strip.text.y = element_text(angle = 0)
)
## TODO: Create a set of small multiples plot from these data
as_tibble(iris) %>%
pivot_longer(
names_to = "part",
values_to = "length",
cols = -Species
) %>%
ggplot(aes(length, Species)) +
geom_point() +
gacet_grid(part~., scale = "free_y", space = "free") +
theme(
strip.text.y = element_text(angle = 0)
)
## TODO: Create a set of small multiples plot from these data
as_tibble(iris) %>%
pivot_longer(
names_to = "part",
values_to = "length",
cols = -Species
) %>%
ggplot(aes(length, Species)) +
geom_point() +
facet_grid(part~., scale = "free_y", space = "free") +
theme(
strip.text.y = element_text(angle = 0)
)
# knitr options
knitr::opts_chunk$set(echo = TRUE)
## Note: No need to edit this chunk!
library(tidyverse)
library(googlesheets4)
url <- "https://docs.google.com/spreadsheets/d/1av_SXn4j0-4Rk0mQFik3LLr-uf0YdA06i3ugE6n-Zdo/edit?usp=sharing"
c_true <- 299792.458 # Exact speed of light in a vacuum (km / s)
c_michelson <- 299944.00  # Michelson's speed estimate (km / s)
meas_adjust <- +92 # Michelson's speed of light adjustment (km / s)
c_michelson_uncertainty <- 51 # Michelson's measurement uncertainty (km / s)
gs4_deauth()
ss <- gs4_get(url)
df_michelson <-
read_sheet(ss) %>%
select(Date, Distinctness, Temp, Velocity) %>%
mutate(
Distinctness = as_factor(Distinctness),
c_meas = Velocity + meas_adjust
)
## TASK: Compute `epsilon_c`
df_q1 <-
df_michelson %>%
mutate(epsilon_c = c_mean - c_true)
## TASK: Compute `epsilon_c`
df_q1 <-
df_michelson %>%
mutate(epsilon_c = c_meas - c_true)
df_q1 %>%
ggplot(aes(epsilon_c)) +
geom_histogram()
## TASK: Estimate `epsilon_mean` and `epsilon_sd` from df_q1
df_q2 <-
df_q1 %>%
summarise(
epsilon_mean = mean(epsilon_c),
epsilon_sd = sd(epsilon_c)
)
## TASK: Estimate `epsilon_mean` and `epsilon_sd` from df_q1
df_q2 <-
df_q1 %>%
summarise(
epsilon_mean = mean(epsilon_c),
epsilon_sd = sd(epsilon_c)
)
View(df_q1)
## TASK: Estimate `epsilon_mean` and `epsilon_sd` from df_q1
df_q2 <-
df_q1 %>%
summarize(
epsilon_mean = mean(epsilon_c),
epsilon_sd = sd(epsilon_c)
)
## TASK: Estimate `epsilon_mean` and `epsilon_sd` from df_q1
df_q2 <-
df_q1 %>%
summarize(
epsilon_mean = mean(epsilon_c),
epsilon_sd = sd(epsilon_c)
)
View(df_q2)
## NOTE: No need to change this!
assertthat::assert_that(abs((df_q2 %>% pull(epsilon_mean)) - 151.942) < 1e-3)
assertthat::assert_that(abs((df_q2 %>% pull(epsilon_sd)) - 79.01055) < 1e-3)
print("Great job!")
## TASK: Compute a 99% confidence interval on the mean of c_meas
C <- 0.99
q <- qnorm( 1 - (1 - C) / 2 )
df_q3 <-
df_q1 %>%
summarize(
c_meas_mean = mean(c_meas),
c_meas_sd = sd(c_meas),
n_samp = n(),
c_lo = c_meas_mean - q * c_meas_sd / sqrt(n_samp),
c_hi = c_meas_mean + q * c_meas_sd / sqrt(n_samp)
)
## NOTE: This checks if the CI contains c_true
(df_q3 %>% pull(c_lo) <= c_true) & (c_true <= df_q3 %>% pull(c_hi))
## TASK: Compute a confidence interval on the mean, use to answer the question
## above
df_sample %>%
summarize(
price_mean = mean(price),
price_sd = sd(price),
price_lo = price_mean - 1.96 * price_sd / sqrt(n()),
price_hi = price_mean + 1.96 * price_sd / sqrt(n())
) %>%
select(price_lo, price_hi)
## TASK: Compute a confidence interval on the mean, use to answer the question
## above
df_sample %>%
summarize(
price_mean = mean(price),
price_sd = sd(price),
price_lo = price_mean - 1.96 * price_sd / sqrt(n()),
price_hi = price_mean + 1.96 * price_sd / sqrt(n())
) %>%
select(price_lo, price_hi)
price_threshold
## TASK: Estimate a confidence interval for the proportion of high-cut diamonds
## in the population. Look to `e-stat09-bootstrap` for starter code.
set.seed(101)
alpha <- 0.01
fit_fun <- function(split_df) {
analysis(split_df) %>%
summarize(estimate = mean((cut == "Premium") | (cut == "Ideal"))) %>%
pull(estimate)
}
df_sample %>%
bootstraps(., times = 1000) %>%
mutate(p_hat = map_dbl(splits, fit_fun)) %>%
summarize(
p_lo = quantile(p_hat, alpha / 2),
p_up = quantile(p_hat, 1 - alpha / 2),
)
## TASK: Compute the population mean of diamond price
df_population %>%
summarize(price = mean(price))
price_threshold
