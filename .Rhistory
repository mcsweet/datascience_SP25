msg = str_c("You have extra houses: ", sampVnum)
)
print("Great work!")
# NOTE: No need to edit; run and answer the questions below
df_sample_random %>%
mutate(last = str_extract(name, "\\w+$")) %>%
count(last) %>%
arrange(desc(n)) %>%
mutate(p = n / sum(n))
## TASK: Write a helper function that takes a dataframe with full names
#  (provided in a `name` column), removes any invalid rows, and computes the
#  proportion of individuals with the user-specified `last` name (returned
#  in an `estimate` column).
name_prevalence <- function(df, last = "Collins") {
df %>%
mutate(last_name = str_extract(name, "\\w+$")) %>%
drop_na(last_name) %>%
count(last_name) %>%
mutate(p = n / sum(n)) %>%
filter(last_name == last) %>%
summarise(
term = last_name,
estimate = p
)
}
## NOTE: No need to change this
# Find the most prevalent name in the data
last_most <-
df_sample_random %>%
mutate(last = str_extract(name, "\\w+$")) %>%
count(last) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(last)
# Ensure correct columns
assertthat::assert_that(
setequal(
tibble(name = c("James")) %>% name_prevalence(., last = "James") %>% names(),
c("term", "estimate")
),
msg = "Your code should result a dataframe with just two columns: `term` and `estimate`"
)
# Ensure NA handling
assertthat::assert_that(
!(tibble(name = c(NA_character_, "James")) %>%
name_prevalence(., last = "James") %>%
pull(estimate) %>%
is.na()),
msg = "Ensure your code properly ignores NA's"
)
# Check for correctness
assertthat::assert_that(
name_prevalence(df_sample_random, last = last_most) %>% pull(estimate) ==
mean(str_detect(df_sample_random$name, last_most), na.rm = TRUE),
msg = "Your code computed the wrong value"
)
print("Nice!")
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
summarize(estimate = mean())
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
View(df_sample_random)
View(df_sample_seq)
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
summarize(estimate = mean(name_prevalence())) %>%
pull(estimate)
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
summarize(estimate = mean(name_prevalence(split_df))) %>%
pull(estimate)
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
mutate(prevalence_data = name_prevalence(analysis(splif_df))) %>%
mutate(estimates = prevalence_data$estimate)
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
mutate(prevalence_data = name_prevalence()) %>%
mutate(estimates = prevalence_data$estimate)
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
mutate(prevalence_data = name_prevalence(., last = "Collins")) %>%
mutate(estimates = prevalence_data$estimate)
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
summarise(prevalence_data = name_prevalence(., last = "Collins")) %>%
summarise(estimates = prevalence_data$estimate)
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
prevalence_data <- name_prevalence(., last = "Collins"))
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
prevalence_data <- name_prevalence(., last = "Collins")
estimates <- prevalence_data$estimate
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
name_prevalence(., last = "Collins")
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
df_interval_bootstrap
{r q2-task}
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
name_prevalence(., last = "Collins")
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
df_interval_bootstrap
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
name_prevalence(., last = "Collins")
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
df_interval_bootstrap
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
name_prevalence(., last = "Regan")
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
df_interval_bootstrap
## NOTE: No need to change this
## Check that data has `p` column and is in descending order
assertthat::assert_that(
all(df_q3 %>%
mutate(d = p - lead(p)) %>%
filter(!is.na(d)) %>%
pull(d) >= 0
)
)
print("Very good!")
## TASK: Set the parameters for this code block
## Select a random sample of houses
n_houses <- 554
n_sample <- 25
set.seed(101)   # Set a seed for reproducibility
df_numbers_random <-
tibble(
house = sample(
1:n_houses,     # All integers from 1 to n_houses
n_sample,       # Size of our sample
replace = FALSE # Sample *WITHOUT* replacement
)
) %>%
# Arrange for our data collection convenience
arrange(house)
# Pull the column so we can list just the house numbers
df_numbers_random %>%
pull(house)
library(tidyverse)
library(rsample)
filename_random <- "./data/helvig-random.csv"
## NOTE: Do not edit this
df_sample_seq <-
read_csv("./data/helvig-seq.csv")%>%
drop_na(name)
df_sample_seq
## TASK: Compute the prevalence and sort
df_q3 <-
df_sample_seq %>%
## TODO: Complete this code
mutate(last_name = sapply(strsplit(as.character(name)," "), function(x) tail(x, 1))) %>%
group_by(last_name) %>%
summarise(
n = n(),
p = n() / nrow(.)
) %>%
arrange(desc(p))
df_q3
#this was how I figued out how to do this math. I just saw how you did it below which makes sense and is much simpler. I am keeping it the way that I did it to show you my own work.
## NOTE: No need to change this
## Check that data has `p` column and is in descending order
assertthat::assert_that(
all(df_q3 %>%
mutate(d = p - lead(p)) %>%
filter(!is.na(d)) %>%
pull(d) >= 0
)
)
print("Very good!")
## TASK: Set the parameters for this code block
## Select a random sample of houses
n_houses <- 554
n_sample <- 25
set.seed(101)   # Set a seed for reproducibility
df_numbers_random <-
tibble(
house = sample(
1:n_houses,     # All integers from 1 to n_houses
n_sample,       # Size of our sample
replace = FALSE # Sample *WITHOUT* replacement
)
) %>%
# Arrange for our data collection convenience
arrange(house)
# Pull the column so we can list just the house numbers
df_numbers_random %>%
pull(house)
## NOTE: No need to change this
assertthat::assert_that(
all(dim(df_numbers_random) == c(25, 1))
)
## NOTE: Do not edit
filename_random
## NOTE: Do not edit
df_sample_random <-
read_csv(filename_random) %>%
select(-4)
df_sample_random
## NOTE: No need to change this
# Check that the dataset has the correct column names
assertthat::assert_that(setequal(
df_sample_random %>% names(),
df_sample_seq %>% names()
))
# Check that all of the house numbers in the dataset match those that were planned
numVsamp <-
anti_join(
df_numbers_random,
df_sample_random %>% distinct(house),
by = "house"
) %>%
pull(house)
assertthat::assert_that(
length(numVsamp) == 0,
msg = str_c("You are missing the houses: ", numVsamp)
)
sampVnum <-
anti_join(
df_sample_random %>% distinct(house),
df_numbers_random,
by = "house"
) %>%
pull(house)
assertthat::assert_that(
length(sampVnum) == 0,
msg = str_c("You have extra houses: ", sampVnum)
)
print("Great work!")
# NOTE: No need to edit; run and answer the questions below
df_sample_random %>%
mutate(last = str_extract(name, "\\w+$")) %>%
count(last) %>%
arrange(desc(n)) %>%
mutate(p = n / sum(n))
## TASK: Write a helper function that takes a dataframe with full names
#  (provided in a `name` column), removes any invalid rows, and computes the
#  proportion of individuals with the user-specified `last` name (returned
#  in an `estimate` column).
name_prevalence <- function(df, last = "Collins") {
df %>%
mutate(last_name = str_extract(name, "\\w+$")) %>%
drop_na(last_name) %>%
count(last_name) %>%
mutate(p = n / sum(n)) %>%
filter(last_name == last) %>%
summarise(
term = last_name,
estimate = p
)
}
## NOTE: No need to change this
# Find the most prevalent name in the data
last_most <-
df_sample_random %>%
mutate(last = str_extract(name, "\\w+$")) %>%
count(last) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(last)
# Ensure correct columns
assertthat::assert_that(
setequal(
tibble(name = c("James")) %>% name_prevalence(., last = "James") %>% names(),
c("term", "estimate")
),
msg = "Your code should result a dataframe with just two columns: `term` and `estimate`"
)
# Ensure NA handling
assertthat::assert_that(
!(tibble(name = c(NA_character_, "James")) %>%
name_prevalence(., last = "James") %>%
pull(estimate) %>%
is.na()),
msg = "Ensure your code properly ignores NA's"
)
# Check for correctness
assertthat::assert_that(
name_prevalence(df_sample_random, last = last_most) %>% pull(estimate) ==
mean(str_detect(df_sample_random$name, last_most), na.rm = TRUE),
msg = "Your code computed the wrong value"
)
print("Nice!")
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
df_sample_random %>%
bootstraps(., times = 1000) %>%
mutate(
estimate = map(
splits,
function(split_df) {
## TODO: Finish this code, using the name_prevalence() helper you implemented
## HINT: Remember that you need to use analysis() when operating on split_df
analysis(split_df) %>%
name_prevalence(., last = "Regan")
}
)
) %>%
## NOTE: No need to edit this line; this uses your bootstrap sample to compute
# a confidence `int`erval using the percentile method
int_pctl(., estimate)
df_interval_bootstrap
## TASK: Compute the prevalence and sort
df_q3 <-
df_sample_seq %>%
## TODO: Complete this code
mutate(last_name = sapply(strsplit(as.character(name)," "), function(x) tail(x, 1))) %>%
group_by(last_name) %>%
summarise(
n = n(),
p = n() / nrow(.)
) %>%
arrange(desc(p))
df_q3
#this was how I figued out how to do this math. I just saw how you did it below which makes sense and is much simpler. I am keeping it the way that I did it to show you my own work.
## NOTE: No need to change this
## Check that data has `p` column and is in descending order
assertthat::assert_that(
all(df_q3 %>%
mutate(d = p - lead(p)) %>%
filter(!is.na(d)) %>%
pull(d) >= 0
)
)
#print("Very good!")
